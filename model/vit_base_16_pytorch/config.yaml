model:
  model_name: Vision Transformer Pytorch
  image_size: 224
  patch_size: 16
  embedding_dim: 768
  num_classes: 13
  num_heads: 12
  num_layers: 12
  pos_embedding_is_Parameter: True
  representation_size: 0
  k_dim: 64
  v_dim: 64
  ffn_hidden_size: 3072
  ffn_mode: 'linear'
  drop_out_radio: 0.1
  is_norm_first: True

train:
  logger_name: 'Vit_Pytorch_For_Rice'
  lr: 0.000025
  Epochs: 50
  batch_size: 32
  model_saved_path: 'model/vit_base_16_pytorch/weights'
  model_saved_name: 'best_epoch_model.pth'
  dataset_path: './rice_data'
  weight_decay: 0.0001
  save_log_dir: './model/vit_base_16_pytorch/logs'